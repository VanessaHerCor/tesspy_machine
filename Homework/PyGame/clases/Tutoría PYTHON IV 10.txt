Tutoría PYTHON IV
Tutoría PYTHON IV
Bien muchachos. Yo creo que de ese reed hay ahí marinch notes.
Lo activé. Yo cierto que increíble, no sabía que estaba. Y no estaba aquí en Zoom.
Interesante. Interesante. Intruso. Muy bien, Me tiraban esa tiraban. Esa visión
me va con las a P: I. S.
Buenas Noches porfa código del chat de tutores están pidiendo código.
Sigamos por acá.
Creo que estamos todos, ¿cierto? Vanesa al tangi al tangi.
Pero puedes hablar, no pasa nada.
Vamos iniciando y ya se va conectando ahorita. Vale, bien muchachos. Entonces
esta primera parte, pues ya vimos un poquito de lo que es. Digamos, como la parte.
Ya vieron lo que es, primero, la el tema de un poco de la visión computacional. Sí,
la visión computacional
es, digámoslo. Ustedes recuerdan la introducción cuando le ha les hablé un poquito de los L. L. Ms.
Y les hablé, digámoslo así, lo que la inteligencia artificial quería imitar Sí,
con respecto, pues, a los humanos de esa parte.
pues aquí la visión computacional. Digamos que una de las aplicaciones más fuertes que tiene es precisamente imitar ese registro que hace el ojo humano vale todo lo que hace el ojo humano como tal.
Entonces, por lo menos está una buena parte sí que en la visión computacional es la detección de objetos.
Normalmente, cuando nos hablan de edición computacional, cuando nos hablan de aplicaciones con visión computacional, ustedes se dieron cuenta de que pueden haber varias cositas y, por por ejemplo, la creación de jueguitos y un tema, por ejemplo, también de que estamos viendo un poco de los dedos jueguitos.
Muchas gracias.
Estamos viendo también un poquito de los jueguitos, sí, pero
pues, claro está, el enfoque es de es del tema más que todo de
es del tema. Más que todo de detección de objetos. Vale como, digamos, como el ojo funcionaría entre comillas. Sí, el ojo Igualmente, lo que hace es, pues, obviamente ver y también detectar objetos. Cierto.
el detecta objetos, detectamos el pasto, el bosque en este caso, detectar la diapositiva, los animales, etcétera. Entonces.
en aplicaciones con visión computacional, sí, nosotros tenemos por lo menos el ojo humano y todo el tema, también de esta parte humana tienen diferentes aplicaciones, diferentes, enfoques, ¿cierto?
Tenemos por lo menos, por ejemplo. Fíjense por acá 1 de los temas es
la clasificación y la localización. Cierto que esta es la más básica de todas, digámoslo. Así que ustedes tienen. Ustedes hacen una red neuronal Porque, bueno, de aquí en adelante ya tomamos a ver neuronales. Sí,
entonces ustedes hacen una red neuronal y la red neuronal. Lo que hace es. Ustedes. No se entrenan con muchas fotos de gatos.
Entonces, si ustedes le dan
una foto. Por ejemplo, un gato con un fondo del bosque arriba tiene un cielo. Si todo esto.
el sistema lo que va a hacer es localizar dónde está el gato, porque en realidad el gato no está en toda la imagen. Está en una parte de ella, sí y precisamente marcarlo.
Esto como tal, Sí, solamente un objeto. Sí, un objeto podría ser esa parte de la localización y de la clasificación sólo en un objeto. Luego evolucionamos un poco y nos fuimos con los múltiples objetos, Sí, con los múltiples objetos
los múltiples objetos ya vienen siendo una parte muy importante, una diferencia muy importante, porque
tenemos detección de objetos y segmentación de instancias.
La La detección de objetos es algo, digámoslo. Así que muchas empresas usan que muchos proyectos usan porque primero es barato. Segundo, no requiere, bueno, sí, precisamente por lo que es barato, no requiere tanta capacidad de cómputo, no requiere tanta el tema de decir de un poco de eso. Y tercero.
normalmente las empresas. Lo que les importa es que clasifiquen. Lo que importa es qué clasifique el sistema. Bien, no importa si hace un cuadrado horrible o hace las cosas como esas. Siempre que el objeto se clasifique bien, todo va a estar bien vale
y de pronto en investigaciones un poco más complejas. Por ejemplo, no sé, estamos hablando de
de de aplicaciones, así como cuales, como, por ejemplo, No sé la criminalidad. Si alguien necesita encontrar un sospechoso por la silueta o por lo menos necesita detectar ciertos animales por su forma, sí
se diseñó la segmentación de distancias que si se dan cuenta, por ejemplo, cuando nosotros clasificamos aquí perros y, por ejemplo, el gato.
tenemos un cuadrado, cierto, pero en el cuadrado no entra todo. Por ejemplo, aquí el perro. Si el perro aquí está en el cuadrado, Pero esta parte no entra esta parte, digamos así, no del perro. Si esta parte tampoco. Entonces hay que diseñar como una silueta cierto para hacer 100 por 100 el perro.
Eso lo que hace es que, pues, llegue el el tema de la sedimentación. La sedimentación es bastante bastante costosa en términos de cómputo, ¿vale?
Es muy costosa en términos de cómputo, pero en muchísimo más precisa.
me hace datos más que todo de espacios de de temas de de contornos. Y todo este tema, la segmentación es muy bacara. Sí.
Entonces, Bueno, otra cosa importante de la segmentación. Si la segmentación.
si se dan cuenta, tiene la capacidad de detectar los múltiples objetos que yo le diga, pero también, y lo más importante, una buena segmentación. Si tiene la capacidad de precisamente dividirme, clasificarme todo lo que está en la imagen, entonces por lo menos él clasifica un color diferente del gato aquí. En este caso, si se dan cuenta, pues esta imagen es la misma que ésta.
Entonces él clasifica en una parte del gato, clasifican otra color. La montaña, clasifican otro color, el cielo y clasifican otro color, el bosque como el el el pasto. Sí, el césped
es eso lo que se quiere? También son la segmentación. Digámoslo así. Si ustedes tienen este tema de la segmentación. Por eso es que es muy carito porque detecta múltiples objetos. En realidad, en 1 sí es más eficiente en cuanto a la silueta.
Entonces, bueno, un poquito también sí
de la edición computacional. Si vamos a tener librerías como opens v
open, serás que es básicamente muchas transformaciones a las imágenes. Háganse de cuenta que es como el editor de Python, ¿sí?
Y opense no va a colaborar mucho en el tema de pronto de de sí de todo este tema de edición, de este tema, de transformación de las imágenes. ¿sí? Y lo más importante aquí, el tema de la transformación de las imágenes es entender que una imagen como tal
s es diferente: escalas
de píxeles, cierto diferentes escalas de colores. En el caso de una imagen en blanco y negro, nosotros tenemos, podemos conceder. Podemos concederla como una matriz de 2 D de 2 dimensiones.
Tiene nomás, pues esta parte y esta parte de acá sí, y cada número de la matriz es un número de terceros, 255 que entre más cercano a 0 es más negro y más cercano a 255 es más blanco. ¿vale?
Entonces esto es lo que le damos a un modelo de visión computacional. Ya lo habíamos visto un poco en el tema de del proyecto final de procesamiento.
pero es un poco. Esto
vale, es un poco de esto, prácticamente yo. Lo que les digo es que el modelo no va a recibir una imagen. Siempre los modelos de mochiler ni de todo, van a recibir números, aunque reciban ustedes creen que reciben imágenes que reciben letras que recién to eso lo transforma a números, y al final, él lo único que entiende es de números.
¿vale?
Lo mismo pasa con
las matrices y las imágenes de la matriz. Por eso es que yo les comentaba que normalmente, cuando 1 trabaja con visión computacional, hay que tener mucho cuidado con la resolución de la imagen.
porque entre más grande es la resolución. Mucho más se va a ampliar de la matriz sin mucho más se va a ampliar la matriz y pues, el aprendizaje. Ustedes saben que pues entre más tengamos datos, pues un modelo más se demora en entrenarse. Vale.
es eso
a color? Simplemente cuando nosotros tenemos imágenes a color, Sí, ya va a ser una matriz de 3 dimensiones.
Va a ser el alto el ancho. Sí como una ma la matriz de escalas y grises. Pero eso se va a multiplicar al final, por el número 3:
¿Qué significa ese número 3:
los canales de color, sí, el azul, el verde, perdón y el rojo, esos colores, Si ustedes los combinan. Pueden hacer todos los demás colores. Sí,
todos los demás colores lo pueden hacer. Digámoslo. Así que es como que sí es. Es la combinación de los colores universales. Vale, cómo funcionan sus pantallas? ¿cómo funciona todo esto? Sí,
es diferente? Combinaciones, tonalidades entre azules, combinaciones entre azul, rojo, verde, etcétera. Vale.
entonces va a tener este por 3 sí y cada pixel. En un caso de de una imagen a color va a tener un valor entre Fíjense acá. Que es una lista entre 0, coma 0, coma, 0, sí, y 255, coma 255, como 255 que, pues el primer elemento, tal vez, pues en este caso la escala de colores: blue, Green y red. Entonces
el primer elemento es: ¿qué tan fuerte está el azul, ¿Qué tan fuerte está el verde y qué tan fuerte está el rojo? Vale, eso es
lo que queremos con esto? ¿vale?
Bien, bueno, bueno, bueno.
vamos a ver. Entonces ya como tal de Opens V. Sí, estos son todos los filtros y operaciones que ustedes pueden ver en openseaven, sí, pero pues honestamente, esto también es mucho de ella. Y no necesitamos normalmente tanta transformación. No necesitamos tanta transformación deme un momentico coloco el código.
Vale, y vamos viéndolo desde Acá
procesamiento de datos. Necesito el de Parquesoft Surf Tail
Sofstein, Parque Piegames.
Y voy a compartir aquí pantalla.
Voy a compartir aquí pantalla de él, porque es listo. O pensé,
entonces aquí muchachos, vamos a ver lo básico. Pensé porque me interesa mucho. Es entrar a yolo lloro. Es realmente el sistema que hace todo el tema de clasificación y todo el tema con the blearming Vale.
Entonces, un poquito de eso. Sí,
un flujo básico de lo que ustedes van a ver con. Ah, bueno, tengo esta imagen de un Pincher.
mis perritos, Los 2 perritos que tengo Son Pinchers: Sí. Uno es criollo. Pincher con cruzado, y el otro es Pinche pincha. Vale.
Bueno, el caso
un pincho. Sí, vamos a tener esa foto del Pincher un poquito de esto. ¿sí? Y vamos a compartir esta es pantalla completa para que vean
él lo que tengo por acá el Bemb
Open, C, D, Open, C, V.
Y vamos a activar el B en script. Ps: Uno listo Ahora, sí. Ahora, Python: flujo básico. Sí,
lo tengo que ver en básico, operaciones, flujo básico.
Punto Pay.
piense por acá. O sea, esto lo más básico que es cargar un modelo, lo que la vida a esos perros no los da en tamaño, entonces den carácter y hasta confianza.
Sí,
pero totalmente de acuerdo, Totalmente de acuerdo, yo. María, totalmente de acuerdo, eso es todo eso estuvo bueno. Bueno el caso. Mi perrito
en familia, mandar solo 1, el pincher. ¡ay, no, Dios mío.
Bueno, el caso
el flujo es muy básico. Si se dan cuenta cómo se lee una imagen Con primero, ¿cómo se importa la librería con Opens. C, Dos. Listo.
¿cómo se llama la librería. O pensé, B Pib, install Open, se ve, no mentira. Open Cb: Dos, creo.
el cristal, o pensé,
Opense de Python Opense de Python. Vale, descárguenla. Véanla. Bien, el superbacán, todo eso. ¿cómo se importa con
C, B, Dos. Vale, Entonces ustedes dentro de ese vídeo van a tener una una una función que se llama Imread. Listo
dentro de esa función también. Cuando ustedes lo ponen, te pueden ver el tamaño, digámoslo así, de los píxeles. Y en este caso, esa imagen del Pincher tiene
2 000 200, 8 768 píxeles
miren un poquito también de los 10 primeros datos de los píxeles. Si se dan cuenta que la matriz es de 3 dimensiones. Una, 2 y 3, pues obviamente aquí esta parte cuentagonales vale.
es de 3 dimensiones.
Es de 3 dimensiones. Entonces por ahí va. La cosa que nos indica que la imagen es a color. Vale.
nos indica que la imagen es a color. Cuando ustedes no sepan de pronto cuál es la imagen y todo eso. Ustedes se van aquí en la forma de la imagen, Si, como en la estructura. Y si no les aparece ese 3, es porque es a blanco y negro. Si les aparece este 3, es porque es acorde. Vale.
es eso.
Y eso es un flujo muy básico, muchachos muy básico y ahorita. Sí, vamos con lo que es vale
que es, las operaciones geométricas, las operaciones geométricas a Python, operaciones geométricas.
perdón básico, operación operaciones geométricas. Sí, tenemos la primera parte que es el redicionamiento. Honestamente, esto es mucha sintaxis y honestamente, esto por lo menos es una primera parte que es
muy de de editor, sí, pero pues me interesa pasar rapidito esa parte para demostrarles lo que sí importa. Realmente Una buena parte de lo que importa.
Pero bueno, redicionamiento, sí es con la función rese, le dan la imagen, y ustedes le dicen cuánto quieren de ancho y cuánto quieren de alto punto como muestra la imagen con Mshot. Este wide Key es si ustedes le dan a la X para bajar esto, pues ya termina ahí la función vale, digámoslo así, de recide
Bien.
recorte. Sí, recorte. Es una parte también importante, porque en este caso, si se dan cuenta, Yo les dije a ustedes que las imágenes son píxeles de una matriz de píxeles, ¿cierto?
Entonces yo, en este caso, yo puedo, a través de esa matriz. Precisamente de píxeles puedo saber exactamente qué, con qué digámoslo así, fila y con qué columna quedarme, por así decirlo. Entonces
piense por acá. Suponemos que esta pues es la columna. Esta es la fin así. Entonces más o menos yo me estoy quedando. Ustedes hacen la cuenta, Sí, entonces
entonces vas hasta aquí, digamos que del 0 al 150 de saque vale del 0 a 150 de aquí. Y del 150 al 300 es como por acá listo.
Digamos que 200 digamos que 200 lo voy a colear con otro colorcito. Es como por aquí. Vale.
bueno, este colorcito no se ve
el el negro. Sí, digamos que
el 200 es por acá. Y el 600 es como más o menos por acá. ¿vale?
Bueno, esto es de la columna. Entonces digámoslo que 200 y 150 de aquí un poquito más por acá. Y 600 y es como por acá vale.
Pero eso de la de la imagen original. ¡ay.
no. Mentira! No, sí. En la imagen original, háganse cuenta de que es la imagen original. ¿sí? Y que yo coloco por lo menos aquí. Si se dan cuenta, vamos a la imagen original que este sea. No sé que este sea 200 que este sea a 3 150, que este sea 100, 50 y que este sea otra listo. Entonces, supongamos que yo tengo eso.
entonces el recorte. Se supone que es lo que va a hacer es coger los primeros 150 datos. Hasta los 350 datos de la matriz. Entonces me va a quedar con esta parte a lo ancho.
Sí, a lo ancho. Me va a quedar con esta parte y de lo alto. Sí, de la columna de 250 a 350. Va a quedar aquí en esta parte.
Ah, sí, y lo demás. Lo descarto. Eso es lo bueno del recorte con él, Sí, como recorta.
pues bueno, normalmente no está bueno, pero pues
ustedes lo pueden hacer con un editor, pero pues es bueno que lo sepan
rotación si ustedes quieren. Ah, bueno, aquí está la imagen recortada. Si se dan cuenta es como más que todo la la el lomo de del perro.
Sí, rotación.
rotación, pues no no interesa mucho el tema. Pero si se dan cuenta, pues simplemente colocar una una división entera entre 2, sí y ya rotándose un poquito, y pues se lo colocan 4, 3 y
entre más cercano a 1, más rotado va a estar si entre más cercano a 0, perdón, más rotado va a estar, o sea rotada, es que va a quedar como en 90 grados. Si.
y pues más arriba, pues ustedes van a experimentar. ¿vale?
Bueno, aquí está aquí. Está también
la matriz de rotación. Sí, la matriz de rotación importante. Esta la edición entera es para colocar un centro, vale para colocar un centro, para colocar un centro.
Y aquí se hace el ángulo. Se le da al centro, se le da el ángulo que quiere, Y pues la escala vale la escala que
imagen desenfocada ojo muy importante. Acá
si ustedes tienen una imagen que tal vez es de muy buena calidad.
Existe la posibilidad de que tenga muchísimos píxeles. ¿sí? Y existe la posibilidad de que al final el entrenamiento sea bastante pesado. Entonces, ¿qué es lo que algunos hacen? Unos hacen el recorte, otros hacen
el tema de la de la de la que del recic sí de colocarlo en otro tamaño diferente, y otros hacen el desenfoque listo. Por ejemplo, ustedes saben que yo aquí puedo reconocer un pinche a pesar de que está desenfocado. Y el modelo sí
puede perder un poquito más de píxeles si puede perder un poco más de píxeles por un entrenamiento en el que vas a ver que eso es un Pincher.
Sí, es cuestión de eso. Entonces, a veces es buena técnica para entrenar los modelos. Pero pues, bueno.
¿cómo hace el desenfoque con 1 que se llama el gausian Blur. Sí, le colocan, por ejemplo, A: bueno, esto se llama un Kernet. Sí,
de hecho, es curioso si sientes curiosidad de que es un Kernel, pero tiene que ver algo con redes neuronales. ¿sí? Y el número siempre de los números que están aquí en esta lista siempre deben de ser impar. Entre más arribita, es más desenfocado y entre más abajito es más enfocado, Vale, ¿Es eso.
Eso también es la detección de orden muchachos.
Supongamos que yo mi proyecto no detecto Pinchers. No detecto si es esto o lo otro yo. Lo que detecto es si un si es un perro o no, Entonces, ¿qué es lo que hago con eso?
Lo que hago es detectar los bordes, ¿sí? Entonces fíjense que en este caso yo puedo convertir toda esa imagen a color.
convertirla en un blanco y negro y en siluetas. El mismo modelo va a estar feliz. Sí, porque se va a entrenar en menos tiempo a consumir. Va a tener menos costo, menos procesamiento y va a predecir igual
todo por el sistema de bordes, y por eso es importante el tema aquí de la detección de bordes, Vale, entonces detección de bordes.
¿con qué se hace con Cani?
Requiere 2 umbrales que es más o menos. Bueno, esto es de experimentación. La verdad. Esto es pura experimentación.
¿y ya
qué tal combinando imágenes? Ah, Bueno, se puede combinar imágenes para ver la diferencia entre entre ambas imágenes. Si ustedes quieren, con la función
H. E. Stack?
Bueno, esto ni siquiera ni siquiera esto debe ser de de Openc. V.
Esto es de
Tener un país, Vale, es de nombre
bien, muchachos, y eso es más o menos las operaciones básicas. Digámoslo así, hay muchas operaciones y se dan cuenta. Acá
Hay muchas operaciones, están por lo menos la operación de umbralización. Si piense, convierte una imagen en escala grises a una imagen binaria blanco y negro, sí,
transformación geométrica. Bueno, esto ya lo vimos operaciones morfológicas y adelgazar, o encoger las áreas blancas de una imagen útil para eliminar pequeños puntos de ruido.
Sí Esto es muy bacano se acuerdan que por lo menos con el Pincher, si se dan cuenta con el pincher, cuando detectábamos los bordes, vamos a ver por acá
cuando detectábamos los bordes.
Aquí hay algunos puntitos que nada que ver. Sí, por lo menos esta parte. Estos están con negro.
por lo menos esta parte Sí, esta pues del piso
en realidad no nos dice nada de si es un pinchero o no.
entonces él también está esta función de de poli de de de no me acuerdo el nombre.
esta función de
de morfológica, al fin y al Cabo adelgaza esas áreas blancas y todo el tema Vale, entonces quita un poquito más el ruido de este tema
y un poquito de eso. Muchachos.
Un poquito de esos, eso no lo vamos a usar aún.
Pero si quieren averiguar un poquito más de openseaven
aquí, les dejo un poquito de información. ¿sí? Un post en medio
que es bastante interesante. Lo pensé, vale, bueno.
bueno, muchachos alguna duda está ahí.
¿qué tal vamos? Vamos. Bien, ¿Tienen alguna duda con esas funciones? Claro.
Todo perfecto? Todo claro, bueno.
María J. Carvajal
María J. Carvajal
24:54
Hay algunos formatos de imagen preferibles sobre otros, o
o siempre va a ser como J, P, G. O los estándares.
Tutoría PYTHON IV
Tutoría PYTHON IV
25:04
En cuanto al entrenamiento del modelo.
María J. Carvajal
María J. Carvajal
25:07
Sí, Pues porque entiendo que el S. B. K y todos nosotros también van cambiando, como como la proporción de píxeles o el tamaño.
Tutoría PYTHON IV
Tutoría PYTHON IV
25:16
Exacto?
Sí, esa esa es muy buena e interesante pregunta: ¿Qué pasa con eso?
Honestamente, muchachos? La verdad en el machine learning. Nosotros nos interesa más que la calidad.
El tema de de local.
Esas aplicaciones son caras. No crean que no son caras de entrenar. Ya tienen un montón de matrices. Y esas matrices tienen un montón de números.
Entonces
yo yo yo preferiblemente, Prefiero las imágenes que no son, por ejemplo, ¿cuál fue la que dice C, B, G, No, me no me acuerdo, el formato, o sea, las iniciales del formato. Pero esa esa vectorial sí.
No la recomiendo. ¿qué? ¿cuál.
María J. Carvajal
María J. Carvajal
26:02
Eso ejerce. Y eso es vectorial.
Tutoría PYTHON IV
Tutoría PYTHON IV
26:05
S B, No la recomiendo tanto porque, como es en formato vectorial, tiende a tener demasiada calidad y donde hay calidad es sinónimo de que hay mucha resolución. Mucho pixel
y el entrenamiento se vuelve más costoso.
Sí, el entrenamiento se vuelve más costoso, entonces
preferiblemente eso depende de el requerimiento de del negocio. Si Si el negocio les dice, no es que yo tengo la plata que me dé la gana y necesito que usted me cree el modelo más preciso del mundo. Ustedes usan un se un C B, Sí, no hay problema.
pero normalmente en las empresas se pide. Es una buena relación, costo, precisión, y para eso normalmente se usan imágenes de un poco de bajita calidad o, en la medida de de lo posible, pequeñas. Si es de buena calidad, sí,
entonces por ese lado, no hay un formato así predilecto, Sí,
entonces es cuestión de eso, de la calidad. Muchachos de la calidad de los costos vale María.
María J. Carvajal
María J. Carvajal
27:16
Fuera del año.
Tutoría PYTHON IV
Tutoría PYTHON IV
27:17
Sí, Sí, perfecto.
Y no hay una pregunta. Otra pregunta. Está ahí todo claro.
Mientras la piensan, voy a ir un momentico al baño. Y ya vuelvo ¿vale?
Y en muchachos. Bueno, entre la tanda por acá vamos a darle por aquí por acá mejor
Se me yo no intergrution ahí. Que eso está
Sets. Puf: Este es duro, este bastante duro.
Mhm: Bueno, sí, vamos a hablar con este
bien muchachos, aunque no lo coloque por acá aunque no lo coloque por acá
ya vamos a meternos en una parte en un territorio un poquito más durito? Sí, en el tema de
un poquito de lo que tiene que ver con la parte de yo. Vale, Yo lo detección. Yo lo detección.
listo yolo. Es un modelo de aplicación con visión computacional. Lo vamos a ver, Vale, yo no hablo ultraditics.
Home: Yo perfecto.
Es prácticamente sí. Es el mejor modelo de clasificación para
que hay, pues ahorita en la actualidad. Sí, Pues de lenguaje abierto y buena relación costo, digámoslo así: costo computacional, precisión. Vale.
Yo lo resulta que ahorita por lo menos hay muchos papers, muchos estudios, muchos modelos que hacen sistemas de clasificación, sistemas de segmentación, sí, pero pues yo lo siempre ha estado muy en la cima. Vale, siempre ha estado muy en la cima.
Entonces, ¿qué es lo que pasa con Yol?
Yo lo es muy bacano. Porque si se dan cuenta, vamos a ver. Yo lo detection las aplicaciones con yo. Lo es muy, muy, muy variadas. Fíjense por lo menos acá que están en una planta de servicio sí en el que no sé, se pueda dar reconocimiento de personas. Por ejemplo, una persona no sé ¿Quién quita
devolviéndonos al al mismo ejemplo atrás, no esa línea amarilla por equis o y el motivo. Entonces el sistema cuando reconoce que una persona cruzó esta línea amarilla, pues da una alerta y así sucesivamente.
También. No hay que irnos
pues allá, si a alguien les interesa más que todo el tema. Eso también. Lo que hace yo lo aquí con este, con este bacanísimo proyecto, sí
de clasificación de los productos de cereal. Fíjense que acá él reconoce donde hay espacios vacíos. Si dentro de los cereales y todo el objeto, si, en caso tal de que haya un objeto, Pues reconocido todo esto vale es muy bacano. Es muy bacano.
¿qué más clasificación de drones, drones, muchos drones, muchos drones
aquí. Clasificación de celular. Digámoslo por este lado, ¿qué más qué más Chaplic Helmut.
Fíjense por acá, para tráfico en caso de fotomultas, ya que se han vuelto muy, muy, muy Ustedes sabían, ustedes sabían que los semáforos inteligentes
fueron, Se supone, pues si funcionarán bien.
pero los semáforos inteligentes fueron hechos con un sistema por detrás. Con yolo.
No sé si lo han visto.
los semáforos inteligentes son los que tienen lo el amarillo y el verde Normalmente se han visto muchos en el sur. Sí, por lo menos sí han pasado por la panamericana por jardín, por jardín plaza, Sí, se ven sobre todo esos semáforos inteligentes. No sé si alguien los ha visto.
pues esos semáforos inteligentes se supone que por detrás tiene un algoritmo con Young
para precisamente reconocimiento de carros y que asimismo, pues se dé paso o no la prioridad a esos carros. ¿vale?
Y es eso
sistema de detección, ambulancias? Y todo esto, o sea, es mucho enfoque. Fíjense lo que les dije de los carros para temas. Fíjense por acá increíble mapa de calor para saber cuál es el carril que más usan muy bacano, muy bacano.
muy, muy, muy bacano conteo.
Entonces.
todo esto es tema de aplicación con visión computacional. Si véanlo bien bacano. Fíjense bien, porque pues es una de las ramas en las que ustedes pueden hacer el proyecto final.
y eso es lo que nosotros queremos con Yolo vale lo que nosotros queremos con You. Entonces, repasen un poquito lo que yo lo yo lo tiene una librería y tiene un leng, un modelo ya predeterminado, sí
por detrás. Fíjense que por lo menos yo lo estaba construido con una cosa: si se dan cuenta, yo lo ya está construido con una cosa que se llama Coco. Datacen
el coco data. Se Si lo veo por acá.
Coco. Voy a colocar coco coco kape points
No, no veo co caso. Les colocan cocoa ta c Sí.
Aquí de ultralitics Cocoatta. Se Bueno, aquí no se ve tan bacano.
Lo mejor es conjunto de datos de cosco.
Yo lo había visto en una parte. Bien, bacana cocoata. Se será aquí este a ver un segundito
para ver la parte de bien bacana coco data, se prohibió
este acá que lo he leí coco Atasset.
Este coco data set Sí, primero es un data sed con 330 0, imágenes.
tiene más de 200 000 etiquetadas, o sea que por lo menos éste diga que sí es un perro, pues es un perro si tiene 1 coma 5 000 000 de instancias de objeto. Eso quiere decir a
que con lo que ustedes vieron significa, si se dan cuenta instancias de segmentación significa que va a haber, en este caso, sí, más de un objeto por
imagen y que yo lo detecta varios objetos por imagen. Entonces piense por acá.
A ver una imagen que sea bien bacana.
Vamos al al Data Zet.
El explor listo.
Fíjense si yo tengo por aquí un perro.
Yo a yo. Voy a colocar las fotos de los perros. ¿vale? Y lo voy a dar a buscar en Data Zet, si quieren. Búsquelo ustedes también por acá
le puedo enviar el link por el por el chat de de Zoom.
Fíjense esto, nosotros le decimos, oye, busca el perro. Pero el adicional.
él es inteligente, ¿sí? Y no solamente busca el perro de la imagen que de hecho, ahí está el perro, sino que también, si tiene yo la posibilidad, también
detecta a los demás objetos que están ahí, Entonces, por ejemplo, detecta un perro. ¿dónde está el perro ahí Si lo dan cuenta, Si ven como la parte violeta, ahí está, detectó
un humano donde está el humano. Aquí estos 3 humanos súper bien detectó una cicla super bien, detectó un barco. Fíjense la la la cosa tan tenaz de este atased, pero es que es bacanísimo, y lo tuvieron que etiquetar los humanos. No lo etiquetó Una guía. Lo tuvieron que etiquetar los humanos
que hasta los barcos que están como a un no le coloco unos
unos 8 o 10 kilómetros, sí los detecta, los detecta, ¿vale?
Miren este caso. También tenemos un perro. Sí, tenemos a humanos y también tenemos carros, ¿sí? E inclusive él detecta camiones que los detecta ¿Cómo las camionetas. Pero pues, bueno, lo mismo acá que un platillo, y todo esto son los objetos que ustedes tienen para detectar.
por ejemplo, también pueden hacer combinaciones. Por ejemplo, yo quiero ver una foto en donde esté un perro y un caballo.
Y fíjense por acá fíjense lo a carísimo. Hay
una, hay humanos y está el el perro y está los caballos, y así sucesivamente.
Vale.
Este lo clasificó. Ay, está el perrito. Na superbacano. Entonces resulta que este es el data. Se con el que se entrena
Yolo. Entonces, ¿qué es lo que hacemos nosotros? Nosotros decimos? Bueno, estos manes gastaron una millonada entrenándolo con tarjeta gráfica y todo lo que nosotros vamos a hacer es coger lo que ellos ya hicieron
entrenarlos con nuestras propias imágenes, y que así sea preciso en imágenes paralizadas que no estén en el Dataced. Por ejemplo, les pongo el ejemplo.
Una una estudiante sí hizo un proyecto con yolo que era de detección de detección de
de de caja de fusibles, porque resulta que ya era arquitecta y una ley colombiana. Creo que limita este tema de los espacios de la caja de fusiles de los enchufes, ¿sí?
Entonces
él lo ella, lo que quería era detectar en donde estaba la caja de fusibles y la caja de la el enchufe, hacer un conteo. Y precisamente saber si estaban cumpliendo o no. Y eso lo puedo conseguir? No gracias a la tasa de coco, Sí, porque la tasación de coco, si se dan cuenta, no tiene ningún lado, un
un enchufe, una caja de fusibles.
sino porque ella de fotos en línea de caja de fusibles de enchufes, pues sobre no sobre entrenó, entrenó de nuevo el modelo, si, por así decirlo, le metió esos datos. Y el modelo fue muy preciso. Ella colocaba fotos de fusibles y enchufes, y el modelo lo reconocía. Y todo es súper interesante. Vale.
es eso. Entonces no vamos a rediseñar la rueda, vamos a usar yolo vale, vamos a usar. Yolo para esto vamos.
Y pues yo lo usaremos. La próxima clase Vale, muchachos, yo lo usaremos la próxima clase.
Entonces, bueno, muchachos hasta aquí, preguntas, inquietudes, dudas, Todo claro.
perfecto.
María J. Carvajal
María J. Carvajal
44:58
Y de esto nos vas a poner algún entregable.
Tutoría PYTHON IV
Tutoría PYTHON IV
45:01
No.
María J. Carvajal
María J. Carvajal
45:03
Vale.
Tutoría PYTHON IV
Tutoría PYTHON IV
45:04
Si ustedes deciden este enfoque, el entregable va a ser en el proyecto final.
María J. Carvajal
María J. Carvajal
45:09
Vale.
Anyi Lisbeth
Anyi Lisbeth
45:14
Profe. El enfoque va a.
Tutoría PYTHON IV
Tutoría PYTHON IV
45:16
Bueno que haya más dudas que.
Anyi Lisbeth
Anyi Lisbeth
45:19
El enfoque va a ser grupal. Es decir, todos tenemos que ponernos de acuerdo cuál será el enfoque o será individual.
Tutoría PYTHON IV
Tutoría PYTHON IV
45:28
No, el enfoque es individual, Y si están trabajando en parejas o en equipos grupal, vale
el grupo decide qué enfoque eligen, pero no no pasa nada. Si María quiere elegir visión computacional, y Angie quiere elegir chat bot, no
yo a las 2 las asesoras Vale, no pasa.
Anyi Lisbeth
Anyi Lisbeth
45:53
Gracias.
Tutoría PYTHON IV
Tutoría PYTHON IV
45:54
Muchachos. No hay más dudas. Entonces, viendo las 9, 15 muchachos. Muchas gracias por la atención
y pues nada espero verlos mañana, si Dios permite. Vale.
bueno, muchachos. Muchas gracias. Que descansen, que disfruten. Vale, Nos vemos mañana, Dios quiere chao.
María J. Carvajal
María J. Carvajal
46:19
El en la.
Tutoría PYTHON IV
Tutoría PYTHON IV
Feliz noche. Chao.