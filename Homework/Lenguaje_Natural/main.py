"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘                 APRENDE PROCESAMIENTO DEL LENGUAJE NATURAL (NLP)             â•‘
â•‘                                                                              â•‘
â•‘              ğŸ“ GuÃ­a PrÃ¡ctica y Educativa de TÃ©cnicas NLP                    â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Â¿QUÃ‰ ES ESTE PROYECTO?
======================

Este proyecto contiene prÃ¡ctica educativa sobre las tÃ©cnicas MÃS IMPORTANTES 
del Procesamiento del Lenguaje Natural (NLP), basadas en las clases que viste:

  â€¢ TutorÃ­a PYTHON IV 17: TokenizaciÃ³n
  â€¢ TutorÃ­a PYTHON IV 18: Lenguaje Natural e IntroducciÃ³n a Embeddings
  â€¢ TutorÃ­a PYTHON IV 19: Lenguaje Natural

CONTENIDO DEL PROYECTO
======================

Este archivo (main.py) es el PUNTO DE ENTRADA. Desde aquÃ­ puedes:

1. Elegir quÃ© tÃ©cnica quieres practicar
2. Cada tÃ©cnica estÃ¡ en su propio archivo en la carpeta 'tecnicas/'

ARCHIVO                    TÃ‰CNICA
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tecnicas/1_bag_of_words.py â†’ Bag of Words (BoW) - LO MÃS BÃSICO
                             â€¢ Cuenta frecuencia de palabras
                             â€¢ Muy simple y rÃ¡pido
                             â€¢ Base de todo lo demÃ¡s

tecnicas/2_tfidf.py        â†’ TF-IDF - MEJORA DE BOW
                             â€¢ Pondera palabras por importancia
                             â€¢ Elimina palabras comunes innecesarias
                             â€¢ EstÃ¡ndar en bÃºsqueda de documentos

tecnicas/3_word2vec.py     â†’ Word2Vec - EMBEDDINGS ESTÃTICOS
                             â€¢ Aprende significado de palabras
                             â€¢ Captura relaciones (anÃ¡logas, similitud)
                             â€¢ Entrada ideal para redes neuronales

tecnicas/4_bert.py         â†’ BERT - EMBEDDINGS CONTEXTUALES â­
                             â€¢ Lo mÃ¡s avanzado aquÃ­
                             â€¢ Entiende contexto
                             â€¢ Base de ChatGPT, Google, etc.

CÃ“MO USAR ESTE PROYECTO
=======================

1ï¸âƒ£  OPCIÃ“N 1: Ejecutar CADA TÃ‰CNICA POR SEPARADO
    â”œâ”€â”€ python tecnicas/1_bag_of_words.py
    â”œâ”€â”€ python tecnicas/2_tfidf.py
    â”œâ”€â”€ python tecnicas/3_word2vec.py
    â””â”€â”€ python tecnicas/4_bert.py

2ï¸âƒ£  OPCIÃ“N 2: Ejecutar ESTE ARCHIVO (main.py) para un MENÃš INTERACTIVO
    â””â”€â”€ python main.py
    (Elige quÃ© tÃ©cnica quieres practicar)

RECOMENDACIÃ“N PARA APRENDER
===========================

ORDEN RECOMENDADO (de fÃ¡cil a difÃ­cil):

  1. BoW        â†’ Entiende lo bÃ¡sico (frecuencias)
  2. TF-IDF     â†’ Mejora sobre BoW (ponderaciÃ³n)
  3. Word2Vec   â†’ Salto conceptual: VECTORES con significado
  4. BERT       â†’ La culminaciÃ³n: contexto + profundidad

DespuÃ©s de ejecutar cada uno:
  âœ“ Lee el cÃ³digo comentado
  âœ“ Entiende quÃ© hace cada secciÃ³n
  âœ“ Experimenta con nuevos ejemplos
  âœ“ Luego pasa al siguiente

NOTAS IMPORTANTES
=================

âš ï¸  Primera ejecuciÃ³n:
    - La primera vez descargarÃ¡ modelos (~500MB)
    - Puede tardar unos minutos
    - DespuÃ©s serÃ¡ mÃ¡s rÃ¡pido

ğŸ“¦ Dependencias necesarias:
    pip install scikit-learn pandas gensim transformers torch

ğŸ¯ Objetivo:
    Entender PROFUNDAMENTE cÃ³mo se convierte TEXTO en NÃšMEROS
    para que las mÃ¡quinas puedan procesarlo

ğŸ’¡ Consejo:
    No solo ejecutes el cÃ³digo, LÃ‰ELO y ENTIÃ‰NDELO
    Cada parte estÃ¡ comentada para tu comprensiÃ³n

================================================================================
"""

import os
import sys
from pathlib import Path


def mostrar_menu():
    """
    Muestra el menÃº interactivo para elegir quÃ© tÃ©cnica practicar
    """
    print("\n" + "="*80)
    print("ğŸ“ MENÃš DE TÃ‰CNICAS NLP")
    print("="*80)
    
    opciones = {
        '1': ('Bag of Words (BoW)', 'tecnicas/1_bag_of_words.py'),
        '2': ('TF-IDF', 'tecnicas/2_tfidf.py'),
        '3': ('Word2Vec', 'tecnicas/3_word2vec.py'),
        '4': ('BERT (Embeddings Contextuales)', 'tecnicas/4_bert.py'),
        '5': ('Ver explicaciÃ³n de todas las tÃ©cnicas', None),
        '0': ('Salir', None)
    }
    
    for clave, (nombre, archivo) in opciones.items():
        print(f"\n   {clave}. {nombre}")
        if archivo:
            print(f"      ğŸ“‚ {archivo}")
    
    print("\n" + "="*80)
    return opciones


def ejecutar_tecnica(ruta_archivo):
    """
    Ejecuta el archivo Python de una tÃ©cnica
    """
    # Convertir a ruta absoluta
    ruta_completa = Path(__file__).parent / ruta_archivo
    
    if not ruta_completa.exists():
        print(f"\nâŒ Error: El archivo {ruta_completa} no existe")
        return
    
    print(f"\nâ–¶ï¸  Ejecutando: {ruta_archivo}")
    print("="*80)
    
    # Ejecutar el archivo
    import subprocess
    resultado = subprocess.run([sys.executable, str(ruta_completa)])
    
    if resultado.returncode != 0:
        print(f"\nâš ï¸  Hubo un error ejecutando {ruta_archivo}")
        print("   AsegÃºrate de tener instaladas todas las dependencias:")
        print("   pip install scikit-learn pandas gensim transformers torch")


def mostrar_explicacion_general():
    """
    Muestra una explicaciÃ³n general del flujo NLP
    """
    print("\n" + "="*80)
    print("ğŸ“š EXPLICACIÃ“N GENERAL: CONVERSIÃ“N DE TEXTO A NÃšMEROS")
    print("="*80)
    
    print("""
Â¿POR QUÃ‰ CONVERTIR TEXTO A NÃšMEROS?
====================================

Las mÃ¡quinas NO entienden texto como nosotros. Los modelos de IA solo entienden
NÃšMEROS. Entonces, el primer paso SIEMPRE es:

    TEXTO â†’ (proceso mÃ¡gico) â†’ NÃšMEROS
    
    Ejemplo:
    --------
    "El perro come"  â†’ [0.23, -0.54, 0.81, 0.12, -0.33, ...]
    
    Estos nÃºmeros representan el SIGNIFICADO y CONTEXTO de la frase.


EL FLUJO COMPLETO (de simple a complejo)
==========================================

1. TOKENIZACIÃ“N
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   "El perro come" â†’ ["El", "perro", "come"]
   
   Â¿QUÃ‰ HACE?
   â€¢ Divide el texto en unidades bÃ¡sicas (palabras, caracteres, etc.)
   â€¢ Primer paso obligatorio
   â€¢ Los tokens se convierten a nÃºmeros


2. BAG OF WORDS (BoW)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Vocabulario: [el, perro, come]
   Vector: [1, 1, 1]  (aparece 1 vez cada palabra)
   
   Â¿QUÃ‰ HACE?
   â€¢ Cuenta cuÃ¡ntas veces aparece cada palabra
   â€¢ Muy simple, muy rÃ¡pido
   â€¢ Pero pierde el orden y el significado


3. TF-IDF
   â”€â”€â”€â”€â”€â”€
   Vector: [0.1, 0.7, 0.6]  (nÃºmeros ponderados)
   
   Â¿QUÃ‰ HACE?
   â€¢ Mejora BoW: da menos peso a palabras comunes ("el")
   â€¢ Da mÃ¡s peso a palabras significativas ("perro")
   â€¢ Mejor para bÃºsqueda de documentos


4. WORD2VEC
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   "perro" â†’ [0.23, -0.54, 0.81, 0.12, -0.33, ...]  (10 nÃºmeros)
   
   Â¿QUÃ‰ HACE?
   â€¢ Cada palabra â†’ vector con SIGNIFICADO
   â€¢ Palabras similares â†’ vectores similares
   â€¢ Permite analogÃ­as: "rey - hombre + mujer â‰ˆ reina"
   â€¢ Pero: mismo vector siempre (no contextual)


5. BERT (Â¡LA REVOLUCIÃ“N!)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Contexto 1: "banco" (instituciÃ³n) â†’ [0.12, 0.89, -0.45, ...]
   Contexto 2: "banco" (asiento)     â†’ [0.34, 0.12, 0.67, ...]
   
   Â¿QUÃ‰ HACE?
   â€¢ Cada palabra â†’ vectores DIFERENTES por CONTEXTO
   â€¢ Entiende mÃºltiples significados
   â€¢ Entiende el contexto de toda la oraciÃ³n
   â€¢ Es la base de ChatGPT y modelos modernos
   â€¢ Pero: es lento y complejo


RESUMEN VISUAL
==============

PrecisiÃ³n:     BoW < TF-IDF < Word2Vec < BERT
               ğŸŸ¢  â†’  ğŸŸ¡    â†’   ğŸŸ     â†’  ğŸ”´

Complejidad:   BoW < TF-IDF < Word2Vec < BERT
               ğŸ’¤  â†’  ğŸ˜´    â†’   ğŸ˜    â†’  ğŸ¤”

Velocidad:     BERT < Word2Vec < TF-IDF < BoW
               ğŸ¢  â†’   ğŸ¦Œ    â†’   ğŸ‡   â†’  âš¡âš¡âš¡

Â¿CUÃNDO USAR CADA UNA?
======================

BoW:
  â€¢ Cuando tienes pocos datos
  â€¢ Cuando necesitas VELOCIDAD
  â€¢ AnÃ¡lisis rÃ¡pido de textos
  â€¢ No necesitas precisiÃ³n extrema

TF-IDF:
  â€¢ BÃºsqueda de documentos (Google)
  â€¢ ClasificaciÃ³n de textos simple
  â€¢ Recomendaciones
  â€¢ Standard en muchas empresas

Word2Vec:
  â€¢ AnÃ¡lisis de similitud
  â€¢ DetecciÃ³n de analogÃ­as
  â€¢ Input para redes neuronales
  â€¢ Cuando necesitas significado pero rapidez

BERT:
  â€¢ ClasificaciÃ³n de textos avanzada
  â€¢ AnÃ¡lisis de sentimientos precisos
  â€¢ Respuestas a preguntas (Q&A)
  â€¢ TraducciÃ³n automÃ¡tica
  â€¢ Cualquier tarea NLP moderna


CONEXIÃ“N CON TUS CLASES
=======================

En la clase 17 (TokenizaciÃ³n):
  âœ“ Aprendiste CÃ“MO dividir texto en tokens
  âœ“ Aprendiste QUE cada token = nÃºmero
  âœ“ IMPORTANTE para entender BoW

En la clase 18 (Lenguaje Natural e IntroducciÃ³n a Embeddings):
  âœ“ Viste vectores y cÃ³mo se relacionan
  âœ“ Aprendiste Bag of Words, TF-IDF, Word2Vec, BERT
  âœ“ Entendiste POR QUÃ‰ se usan embeddings

En la clase 19 (Lenguaje Natural):
  âœ“ Viste mÃ¡s sobre embeddings contextuales
  âœ“ Entendiste las limitaciones de diccionarios
  âœ“ Viste por quÃ© BERT es superior


PRÃ“XIMOS PASOS EN TU CURSO
==========================

1. Domina estas 4 tÃ©cnicas (estÃ¡s aquÃ­ ğŸ“)
2. AprenderÃ¡s sobre Transformers (arquitectura de BERT)
3. AprenderÃ¡s Fine-tuning (adaptar BERT a tus problemas)
4. AplicarÃ¡s esto al PROYECTO FINAL


Â¡EMPECEMOS!
===========
""")


def main():
    """
    FunciÃ³n principal que muestra el menÃº y ejecuta las opciones
    """
    
    # Mostrar introducciÃ³n al iniciar
    print(__doc__)
    
    while True:
        opciones = mostrar_menu()
        
        seleccion = input("\nğŸ¯ Elige una opciÃ³n (0-5): ").strip()
        
        if seleccion not in opciones:
            print("\nâŒ OpciÃ³n no vÃ¡lida. Intenta de nuevo.")
            continue
        
        nombre, archivo = opciones[seleccion]
        
        if seleccion == '0':
            print("\nğŸ‘‹ Â¡Gracias por practicar NLP! Sigue estudiando ğŸ“š")
            break
        
        elif seleccion == '5':
            mostrar_explicacion_general()
            input("\nğŸ“Œ Presiona Enter para volver al menÃº...")
        
        else:
            ejecutar_tecnica(archivo)
            input("\nğŸ“Œ Presiona Enter para volver al menÃº...")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Programa interrumpido por el usuario")
    except Exception as e:
        print(f"\nâŒ Error inesperado: {e}")
        print("\nAsegÃºrate de tener instaladas las dependencias:")
        print("pip install scikit-learn pandas gensim transformers torch")
